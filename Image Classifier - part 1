# Imports here
import torch
from torch import nn
from torch import optim
import torch.nn.functional as F
import torchvision
from torchvision import datasets, transforms, models
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from collections import OrderedDict
import time
from PIL import Image
import random, os


# Loading data
data_dir = 'flowers'
train_dir = data_dir + '/train'
valid_dir = data_dir + '/valid'
test_dir = data_dir + '/test'


# TODO: Define your transforms for the training, validation, and testing sets
train_transforms = transforms.Compose([transforms.RandomRotation(40),
                                       transforms.RandomResizedCrop(224),
                                       transforms.RandomHorizontalFlip(),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406],
                                                            [0.229, 0.224, 0.225])])

valid_transforms = transforms.Compose([transforms.Resize(255),
                                      transforms.CenterCrop(224),
                                      transforms.ToTensor(),
                                      transforms.Normalize([0.485, 0.456, 0.406],
                                                           [0.229, 0.224, 0.225])])

test_transforms = transforms.Compose([transforms.Resize(255),
                                      transforms.CenterCrop(224),
                                      transforms.ToTensor(),
                                      transforms.Normalize([0.485, 0.456, 0.406],
                                                           [0.229, 0.224, 0.225])])


# TODO: Load the datasets with ImageFolder
train_data = datasets.ImageFolder(train_dir, transform=train_transforms) 

valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)

test_data = datasets.ImageFolder(test_dir, transform=test_transforms)


# TODO: Using the image datasets and the trainforms, define the dataloaders
trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)

validloader = torch.utils.data.DataLoader(valid_data, batch_size=64, shuffle=True)

testloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)


# Label mapping

import json

with open('cat_to_name.json', 'r') as f:
    cat_to_name = json.load(f)
    


# TODO: Build and train your network

# Enabling cuda when available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Choosing model
model = models.densenet161(pretrained=True)

# Freezing parameters 
for param in model.parameters():
    param.requires_grad = False

#Defining classifier    
model.classifier = nn.Sequential(nn.Linear(2208, 420),
                                 nn.ReLU(),
                                 nn.Dropout(0.4),
                                 nn.Linear(420, 102),
                                 nn.LogSoftmax(dim=1))
    
criterion = nn.NLLLoss()


# Only training the classifier parameters
optimizer = optim.Adam(model.classifier.parameters(), lr=0.002)

model.to(device);



# Saving checkpoint
# TODO: Save the checkpoint 
model.class_to_idx = train_data.class_to_idx

checkpoint = {'input_size': 1024,
              'output_size': 102,
              'arch': 'densenet161',
              'classifier' : model.classifier,
              'learning_rate': 0.002,
              'epochs': epochs,
              'class_to_idx': model.class_to_idx,
              'state_dict': model.state_dict(),
              'optimizer': optimizer.state_dict(),
             }

torch.save(checkpoint, 'model_checkpoint1.pth')




# Loading checkpoint
# TODO: Write a function that loads a checkpoint and rebuilds the model
def load_checkpoint(filepath):
    checkpoint = torch.load(filepath)
    model = getattr(torchvision.models, checkpoint['arch'])(pretrained=True)
    model.classifier = checkpoint['classifier']
    learning_rate = checkpoint['learning_rate']
    model.epochs = checkpoint['epochs']
    model.optimizer = checkpoint['optimizer']
    model.load_state_dict(checkpoint['state_dict'])
    model.class_to_idx = checkpoint['class_to_idx']

    
    return model

load_checkpoint('model_checkpoint1.pth')
print(model)


# Processing image
def process_image(image):
    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,
        returns an Numpy array
    '''
    
    # TODO: Process a PIL image for use in a PyTorch model
    
    #Resize the images where the shortest side is 256 pixels, keeping the aspect ratio.
    size = (256, 256)
    image.thumbnail(size, Image.ANTIALIAS)
    
    #Crop image to center at 224, 224
    width, height = image.size  # Get dimensions

    left = (width - 224)/2
    top = (height - 224)/2
    right = (width + 224)/2
    bottom = (height + 224)/2
    
    
    
# Predict function
def predict(image_path, model, topk=5):
    ''' Predict the class (or classes) of an image using a trained deep learning model.
    '''
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    
    # TODO: Implement the code to predict the class from an image file
    image = Image.open(image_path)
    
    # Processing image
    image = process_image(image)
    image = torch.from_numpy(image).unsqueeze_(0)
    
    # Loading model
    load_checkpoint("model_checkpoint1.pth")
    
    # Processing image through model
    model.eval()
    with torch.no_grad():
        #for images, labels in testloader:
        #    images, labels = images.to(device), labels.to(device)
            
        log_probs = model.forward(image)
        probs = torch.exp(log_probs)
        top_probs, top_class = probs.topk(5)
       
        # class_to_idx dictionary
        idx_to_class = { v : k for k,v in model.class_to_idx.items()}
            
        return top_probs, top_class

image_path = 'flowers/test/12/image_03994.jpg'

model = load_checkpoint('model_checkpoint1.pth')
probs, classes = predict(image_path, model)
print(probs)
print(probs.shape)
print(classes)
print(classes.shape)

    # Crop the center of the image
    image = image.crop((left, top, right, bottom))
    
    #Convert the image into numpy array.
    np_image = np.array(image)
    
    
    #Normalize image subtracting mean and dividing by Standard Deviation.
    np_image = np_image / 255
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    np_image = (np_image - mean) / std
    
    #Return transpose of numpy image with color channel at first dim.
    np_image.transpose((2, 0, 1))
    
    return np_image
